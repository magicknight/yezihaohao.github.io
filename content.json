{"meta":{"title":"个人博客","subtitle":"个人分享","description":"学习总结 思考感悟","author":"chenghao","url":"http://yoursite.com"},"pages":[{"title":"about","date":"un44fin44","updated":"un44fin44","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于测试呵呵我只是想安静地写前端"},{"title":"tags","date":"un44fin44","updated":"un44fin44","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"un44fin44","updated":"un44fin44","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"Hello World","date":"un44fin44","updated":"un44fin44","comments":true,"path":"hello-world.html","permalink":"http://yoursite.com/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"}],"posts":[{"title":"Nodejs爬虫--抓取豆瓣电影网页数据（上）","slug":"Nodejs爬虫-抓取豆瓣电影网页数据（上）","date":"un44fin44","updated":"un44fin44","comments":true,"path":"2017/02/09/Nodejs爬虫-抓取豆瓣电影网页数据（上）/","link":"","permalink":"http://yoursite.com/2017/02/09/Nodejs爬虫-抓取豆瓣电影网页数据（上）/","excerpt":"之前写了一个nodejs的开源爬虫小项目，补上博客详细解析下代码。 PS：共有上下两篇，第一篇讲从网站上抓取数据，第二篇讲将抓取的数据存入mongodb数据库。 我们快速开始吧首先，安装nodejs，然后用npm工具初始化资源管理配置文件：package.json1npm init 然后用npm安装相关库文件：1npm install --save-dev superagent cheerio eventproxy async 需要用到的nodejs模块如下(具体用法请查询网上相关资料)：12345let superagent = require('superagent'), //nodejs里面一个非常方便的客户端代理请求模块，支持get,post,put,delete等 cheerio = require('cheerio'), //类似于jQuery的DOM操作模块，可以提取html中想要的信息 eventproxy = require('eventproxy'), //控制异步请求并发，可以监听请求，使得某些请求完毕之后在发送请求 assert = require('assert'), //异常抛出判断模块，assert.equal(err, null); 如果err不为null,则直接抛出异常 async = require('async'); //控制请求并发连接数","text":"之前写了一个nodejs的开源爬虫小项目，补上博客详细解析下代码。 PS：共有上下两篇，第一篇讲从网站上抓取数据，第二篇讲将抓取的数据存入mongodb数据库。 我们快速开始吧首先，安装nodejs，然后用npm工具初始化资源管理配置文件：package.json1npm init 然后用npm安装相关库文件：1npm install --save-dev superagent cheerio eventproxy async 需要用到的nodejs模块如下(具体用法请查询网上相关资料)：12345let superagent = require('superagent'), //nodejs里面一个非常方便的客户端代理请求模块，支持get,post,put,delete等 cheerio = require('cheerio'), //类似于jQuery的DOM操作模块，可以提取html中想要的信息 eventproxy = require('eventproxy'), //控制异步请求并发，可以监听请求，使得某些请求完毕之后在发送请求 assert = require('assert'), //异常抛出判断模块，assert.equal(err, null); 如果err不为null,则直接抛出异常 async = require('async'); //控制请求并发连接数 用superagent请求豆瓣的某个接口，并把所有的页面链接放到一个数组里面，用eventproxy控制监听该请求结束之后才开始请求相应的详情页面。12345678superagent.get(URL) .end((err, res) =&gt; &#123; let _pageUrls = []; res.body.forEach((val) =&gt; &#123; _pageUrls.push(val.url); &#125;); ep.emit('pageUrls', _pageUrls); //监听相关实例，完成之后告诉pageUrls &#125;) 监听事件完成之后，执行请求相应的豆瓣电影详情页面.并用async控制请求的并发量，可以降低请求的频率和速度123456789101112131415161718192021222324252627let ep = eventproxy.create('pageUrls', (pageUrls) =&gt; &#123; //创建一个监听实例 let _http = (url, callback) =&gt; &#123; let _delay = parseInt((Math.random() * 30000000) % 1000, 10); //随机延时请求 superagent.get(url) .end((err, res) =&gt; &#123; var $ = cheerio.load(res.text); //用cheerio获取整个页面DOM对象 var _data = &#123;title:'', type: '', directories: '', scriptwriter: '', actors: ''&#125;; _data.title = $('#content h1 span').text(); _data.directories = $('#info .attrs').eq(0).text(); _data.scriptwriter = $('#info .attrs').eq(1).text(); _data.actors = $('#info .attrs').eq(2).text(); $('span[property=\"v:genre\"]').each(function (index) &#123; _data.type += ($(this).text() + (index == $('span[property=\"v:genre\"]').length - 1 ? '' : '、')); &#125;); console.log(_data); &#125;); setTimeout(() =&gt; &#123; callback(null, url); &#125;, _delay); &#125;; async.mapLimit(pageUrls, 3, (url, callback) =&gt; &#123; //用async 的 mapLimit(arr, limit, iterator, callback) 接口控制请求并发量为3 _http(url, callback); &#125;, (err, res) =&gt; &#123; assert.equal(err, null); &#125;)&#125;); 本章节结束，未完待续…下期是怎么将抓取的数据存入mongodb数据库！","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/categories/爬虫/"}],"tags":[{"name":"Nodejs","slug":"Nodejs","permalink":"http://yoursite.com/tags/Nodejs/"}]}]}