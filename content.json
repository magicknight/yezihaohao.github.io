{"meta":{"title":"前端博客","subtitle":"前端分享","description":"学习总结 思考感悟","author":"chenghao","url":"http://yoursite.com"},"pages":[{"title":"Hello World","date":"un44fin44","updated":"un44fin44","comments":true,"path":"hello-world.html","permalink":"http://yoursite.com/hello-world.html","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment"},{"title":"about","date":"un44fin44","updated":"un44fin44","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"关于测试呵呵我只是想安静地写前端"},{"title":"tags","date":"un44fin44","updated":"un44fin44","comments":true,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"categories","date":"un44fin44","updated":"un44fin44","comments":true,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"imgs","date":"un66fin66","updated":"un66fin66","comments":true,"path":"imgs/index.html","permalink":"http://yoursite.com/imgs/index.html","excerpt":"","text":""}],"posts":[{"title":"Nodejs爬虫--抓取豆瓣电影网页数据（下）","slug":"Nodejs爬虫-抓取豆瓣电影网页数据（下）","date":"un66fin66","updated":"un66fin66","comments":true,"path":"2017/02/11/Nodejs爬虫-抓取豆瓣电影网页数据（下）/","link":"","permalink":"http://yoursite.com/2017/02/11/Nodejs爬虫-抓取豆瓣电影网页数据（下）/","excerpt":"接着上篇 Nodejs爬虫–抓取豆瓣电影网页数据（上） 本篇主要描述将上次抓取的数据存入mongodb数据库 前提：百度或谷歌mongodb的安装教程，安装本地并成功运行 推荐一款mongodb数据库可视化管理工具：Robomongo。可以加群264591039获取安装包或自行寻找资源 首先用npm安装第三方数据库操作包：mongoose.关于mongoose详情请查看官方文档1npm install --save-dev mongoose 引入mongoose包开始对mongodb进行管理当前目录下新建一个mongo.js文件方便管理，在该文件中引入相关包：12let mongoose = require('mongoose'), assert = require('assert');","text":"接着上篇 Nodejs爬虫–抓取豆瓣电影网页数据（上） 本篇主要描述将上次抓取的数据存入mongodb数据库 前提：百度或谷歌mongodb的安装教程，安装本地并成功运行 推荐一款mongodb数据库可视化管理工具：Robomongo。可以加群264591039获取安装包或自行寻找资源 首先用npm安装第三方数据库操作包：mongoose.关于mongoose详情请查看官方文档1npm install --save-dev mongoose 引入mongoose包开始对mongodb进行管理当前目录下新建一个mongo.js文件方便管理，在该文件中引入相关包：12let mongoose = require('mongoose'), assert = require('assert'); 获取表构造器Schema并映射mongodb相应的collection12345678910111213let Schema = mongoose.Schema;let filmSchema = new Schema(&#123; //自定义相应的表数据字段 title: String, type: String, directories: String, scriptwriter: String, actors: String &#125;);//映射collection并生成model对象用于管理数据表的增删改查//默认是映射到名为films的collection//若自定义表明则：let filmSchema = new Schema(&#123;..&#125;, &#123; collection: 'data' &#125;); 'data'即为自定义名称let Film = mongoose.model('Film', filmSchema); 连接mongodb数据库并exports Film对象123456789let db = mongoose.connect('mongodb://127.0.0.1:27017/spider');db.connection.on('error', (err) =&gt; &#123; console.log(`数据库连接失败：$&#123;err&#125;`);&#125;);db.connection.on('open', () =&gt; &#123; console.log('数据库连接成功');&#125;);module.exports = &#123;Film: Film&#125;; 在spider.js中引入Film对象并添加入库操作代码123456789101112131415161718let mongo = require('./mongo');//在请求网页的end函数中添加入库操作xxxx.end((err, res) =&gt; &#123; var $ = cheerio.load(res.text); //用cheerio获取整个页面DOM对象 var _data = &#123;title:'', type: '', directories: '', scriptwriter: '', actors: ''&#125;; _data.title = $('#content h1 span').text(); _data.directories = $('#info .attrs').eq(0).text(); _data.scriptwriter = $('#info .attrs').eq(1).text(); _data.actors = $('#info .attrs').eq(2).text(); $('span[property=\"v:genre\"]').each(function (index) &#123; _data.type += ($(this).text() + (index == $('span[property=\"v:genre\"]').length - 1 ? '' : '、')); &#125;); console.log(_data); mongo.Film.create(_data, (err, doc) =&gt; &#123; assert.equal(err, null); console.log(doc); &#125;);&#125;); 运行spider.js，并查看数据库中的数据12node spider.js//用上述提到的可视化工具查看数据库是否成功有数据入库","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/categories/爬虫/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://yoursite.com/tags/Javascript/"},{"name":"Nodejs","slug":"Nodejs","permalink":"http://yoursite.com/tags/Nodejs/"}]},{"title":"Javascript正则表达式整合","slug":"Javascript正则表达式整合","date":"un55fin55","updated":"un55fin55","comments":true,"path":"2017/02/10/Javascript正则表达式整合/","link":"","permalink":"http://yoursite.com/2017/02/10/Javascript正则表达式整合/","excerpt":"项目中常用正则表达式使用整合大全提取网页标签内容一.单个标签提取123let str = `&lt;a class=\"menu\"&gt;GitHub&lt;/a&gt;`;let content = str.match(/&lt;a class=\"menu\"&gt;([\\s\\S]+)&lt;\\/a&gt;/)[1];","text":"项目中常用正则表达式使用整合大全提取网页标签内容一.单个标签提取123let str = `&lt;a class=\"menu\"&gt;GitHub&lt;/a&gt;`;let content = str.match(/&lt;a class=\"menu\"&gt;([\\s\\S]+)&lt;\\/a&gt;/)[1]; 不定时更新中…","categories":[{"name":"正则表达式","slug":"正则表达式","permalink":"http://yoursite.com/categories/正则表达式/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://yoursite.com/tags/Javascript/"}]},{"title":"Nodejs爬虫--抓取豆瓣电影网页数据（上）","slug":"Nodejs爬虫-抓取豆瓣电影网页数据（上）","date":"un44fin44","updated":"un66fin66","comments":true,"path":"2017/02/09/Nodejs爬虫-抓取豆瓣电影网页数据（上）/","link":"","permalink":"http://yoursite.com/2017/02/09/Nodejs爬虫-抓取豆瓣电影网页数据（上）/","excerpt":"之前写了一个nodejs的开源爬虫小项目，补上博客详细解析下代码。 PS：共有上下两篇，第一篇讲从网站上抓取数据，第二篇讲将抓取的数据存入mongodb数据库。 我们快速开始吧首先，安装nodejs，然后用npm工具初始化资源管理配置文件：package.json新建spider文件夹，在该文件夹下面初始化package.json1npm init 然后用npm安装相关库文件：1npm install --save-dev superagent cheerio eventproxy async 在文件夹下面新建spider.js, 在文件中引入需要用到的nodejs模块如下(具体用法请查询网上相关资料)：12345let superagent = require('superagent'), //nodejs里面一个非常方便的客户端代理请求模块，支持get,post,put,delete等 cheerio = require('cheerio'), //类似于jQuery的DOM操作模块，可以提取html中想要的信息 eventproxy = require('eventproxy'), //控制异步请求并发，可以监听请求，使得某些请求完毕之后在发送请求 assert = require('assert'), //异常抛出判断模块，assert.equal(err, null); 如果err不为null,则直接抛出异常 async = require('async'); //控制请求并发连接数","text":"之前写了一个nodejs的开源爬虫小项目，补上博客详细解析下代码。 PS：共有上下两篇，第一篇讲从网站上抓取数据，第二篇讲将抓取的数据存入mongodb数据库。 我们快速开始吧首先，安装nodejs，然后用npm工具初始化资源管理配置文件：package.json新建spider文件夹，在该文件夹下面初始化package.json1npm init 然后用npm安装相关库文件：1npm install --save-dev superagent cheerio eventproxy async 在文件夹下面新建spider.js, 在文件中引入需要用到的nodejs模块如下(具体用法请查询网上相关资料)：12345let superagent = require('superagent'), //nodejs里面一个非常方便的客户端代理请求模块，支持get,post,put,delete等 cheerio = require('cheerio'), //类似于jQuery的DOM操作模块，可以提取html中想要的信息 eventproxy = require('eventproxy'), //控制异步请求并发，可以监听请求，使得某些请求完毕之后在发送请求 assert = require('assert'), //异常抛出判断模块，assert.equal(err, null); 如果err不为null,则直接抛出异常 async = require('async'); //控制请求并发连接数 用superagent请求豆瓣的某个接口，并把所有的页面链接放到一个数组里面，用eventproxy控制监听该请求结束之后才开始请求相应的详情页面。12345678superagent.get(URL) .end((err, res) =&gt; &#123; let _pageUrls = []; res.body.forEach((val) =&gt; &#123; _pageUrls.push(val.url); &#125;); ep.emit('pageUrls', _pageUrls); //监听相关实例，完成之后告诉pageUrls &#125;) 监听事件完成之后，执行请求相应的豆瓣电影详情页面.并用async控制请求的并发量，可以降低请求的频率和速度123456789101112131415161718192021222324252627let ep = eventproxy.create('pageUrls', (pageUrls) =&gt; &#123; //创建一个监听实例 let _http = (url, callback) =&gt; &#123; let _delay = parseInt((Math.random() * 30000000) % 1000, 10); //随机延时请求 superagent.get(url) .end((err, res) =&gt; &#123; var $ = cheerio.load(res.text); //用cheerio获取整个页面DOM对象 var _data = &#123;title:'', type: '', directories: '', scriptwriter: '', actors: ''&#125;; _data.title = $('#content h1 span').text(); _data.directories = $('#info .attrs').eq(0).text(); _data.scriptwriter = $('#info .attrs').eq(1).text(); _data.actors = $('#info .attrs').eq(2).text(); $('span[property=\"v:genre\"]').each(function (index) &#123; _data.type += ($(this).text() + (index == $('span[property=\"v:genre\"]').length - 1 ? '' : '、')); &#125;); console.log(_data); &#125;); setTimeout(() =&gt; &#123; callback(null, url); &#125;, _delay); &#125;; async.mapLimit(pageUrls, 3, (url, callback) =&gt; &#123; //用async 的 mapLimit(arr, limit, iterator, callback) 接口控制请求并发量为3 _http(url, callback); &#125;, (err, res) =&gt; &#123; assert.equal(err, null); &#125;)&#125;); 本章节结束，未完待续…下期是怎么将抓取的数据存入mongodb数据库！","categories":[{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/categories/爬虫/"}],"tags":[{"name":"Javascript","slug":"Javascript","permalink":"http://yoursite.com/tags/Javascript/"},{"name":"Nodejs","slug":"Nodejs","permalink":"http://yoursite.com/tags/Nodejs/"}]}]}